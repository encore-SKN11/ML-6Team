{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from itertools import cycle\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'meeting'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names = [\n",
    "    \"make\", \"address\", \"all\", \"3d\", \"our\", \"over\", \"remove\", \"internet\", \"order\", \"mail\",\n",
    "    \"receive\", \"will\", \"people\", \"report\", \"addresses\", \"free\", \"business\", \"email\", \"you\",\n",
    "    \"credit\", \"your\", \"font\", \"000\", \"money\", \"hp\", \"hpl\", \"george\", \"650\", \"lab\", \"labs\",\n",
    "    \"telnet\", \"857\", \"data\", \"415\", \"85\", \"technology\", \"1999\", \"parts\", \"pm\", \"direct\",\n",
    "    \"cs\", \"meeting\", \"original\", \"project\", \"re\", \"edu\", \"table\", \"conference\", \"freq_;\",\n",
    "    \"freq_(\", \"freq_[\", \"freq_!\", \"freq_$\", \"freq_#\", \"capital_run_length_average\",\n",
    "    \"capital_run_length_longest\", \"capital_run_length_total\", \"is_spam\"]\n",
    "\n",
    "spam_df = pd.read_csv(\"data/spambase.data\",header=None, names=names)\n",
    "\n",
    "spam_X = spam_df.drop('is_spam', axis=1)\n",
    "spam_y = spam_df['is_spam']\n",
    "\n",
    "# print(spam_y[spam_y==0].count() / 4601 * 100)\n",
    "# print(spam_y[spam_y==1].count() / 4601 * 100)\n",
    "names[41]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 데이터 정규화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "standard_sc = StandardScaler()\n",
    "spam_X = standard_sc.fit_transform(spam_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 데이터 분할"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(spam_X,\n",
    "                                                    spam_y,\n",
    "                                                    test_size=0.2,\n",
    "                                                    stratify=spam_y,\n",
    "                                                    random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 모델 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.metrics import precision_score\n",
    "\n",
    "\n",
    "lr_clf =  LogisticRegression(max_iter=1000)\n",
    "dt_clf =  DecisionTreeClassifier(max_features='sqrt')\n",
    "svm_clf =  SVC(max_iter=1000)\n",
    "knn_clf =  KNeighborsClassifier()\n",
    "xgb_clf =  XGBClassifier(n_estimators=500)\n",
    "lgbm_clf =  LGBMClassifier(n_estimators=500)\n",
    "hist_gb_clf =  HistGradientBoostingClassifier(max_bins=255,\n",
    "                                              early_stopping=True,\n",
    "                                              n_iter_no_change=5)\n",
    "\n",
    "models_names = [lr_clf, dt_clf, svm_clf, knn_clf, xgb_clf, lgbm_clf, hist_gb_clf]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 파라미터 목록"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_params =  {\n",
    "            'penalty' : ['l1', 'l2'],\n",
    "            'C' : np.arange(200) / 10,\n",
    "            'solver' : ['lbfgs', 'newton-cg', 'liblinear']\n",
    "            }\n",
    "dt_params =  {\n",
    "            'max_depth' : range(1, 8),\n",
    "            'min_samples_split' : range(2, 11),\n",
    "            'min_samples_leaf' : range(2, 11)\n",
    "            }\n",
    "svm_params =  {\n",
    "            'C' : np.arange(200) / 10,\n",
    "            'kernel' : ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "            }\n",
    "knn_params =  {\n",
    "            'n_neighbors' : range(3, 12, 2),\n",
    "            'algorithm' : ['auto', 'ball_tree', 'kd_tree', 'brute']\n",
    "            }\n",
    "xgb_params =  {\n",
    "            'learning_rate' : np.arange(101) / 100,\n",
    "            'max_depth' : range(3, 9)\n",
    "            }\n",
    "lgbm_params =  {\n",
    "            'learning_rate' : np.arange(101) / 100,\n",
    "            'max_depth' : range(3, 9)\n",
    "            }\n",
    "hist_gb_params =  {\n",
    "            'learning_rate' : np.arange(101) / 100,\n",
    "            'max_depth' : range(3, 9),\n",
    "            \n",
    "            }\n",
    "\n",
    "model_params = [lr_params, dt_params, svm_params, knn_params, xgb_params, lgbm_params, hist_gb_params]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 평가지표"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score\n",
    "\n",
    "def evaluate_score(y_true, y_pred):\n",
    "    precision = precision_score(y_true, y_pred)\n",
    "    recall = recall_score(y_true, y_pred)\n",
    "    print('precision: {0:.6f}, recall: {1:.6f}'\\\n",
    "          .format(precision, recall))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 하이퍼 파라미터 최적화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# model_best_params = []\n",
    "# model_best_estimators = []\n",
    "\n",
    "# for idx, model_ in enumerate(models_names):\n",
    "#     rd_search = RandomizedSearchCV(model_, model_params[idx], cv=5, n_iter=100, random_state=0)\n",
    "#     rd_search.fit(X_train, y_train)\n",
    "    \n",
    "#     model_best_params.append(rd_search.best_params_)\n",
    "#     model_best_estimators.append(rd_search.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from joblib import dump\n",
    "# file_names = ['lr_clf.joblib', 'dt_clf.joblib', 'svm_clf.joblib', 'knn_clf.joblib', 'xgb_clf.joblib', 'lgbm_clf.joblib', 'hist_gb_clf.joblib']\n",
    "\n",
    "# for idx, file_name in enumerate(file_names):\n",
    "#     dump(model_best_estimators[idx], file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for idx, best_param in enumerate(model_best_params):\n",
    "#     print(f'{file_names[idx]} | best parameters:\\n{best_param}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lr_clf.joblib | best parameters:\n",
    "{'solver': 'liblinear', 'penalty': 'l1', 'C': np.float64(3.7)}\n",
    "\n",
    "dt_clf.joblib | best parameters:\n",
    "{'min_samples_split': 10, 'min_samples_leaf': 4, 'max_depth': 7}\n",
    "\n",
    "svm_clf.joblib | best parameters:\n",
    "{'kernel': 'rbf', 'C': np.float64(6.9)}\n",
    "\n",
    "knn_clf.joblib | best parameters:\n",
    "{'n_neighbors': 5, 'algorithm': 'auto'}\n",
    "\n",
    "xgb_clf.joblib | best parameters:\n",
    "{'max_depth': 4, 'learning_rate': np.float64(0.06)}\n",
    "\n",
    "lgbm_clf.joblib | best parameters:\n",
    "{'max_depth': 7, 'learning_rate': np.float64(0.05)}\n",
    "\n",
    "hist_gb_clf.joblib | best parameters:\n",
    "{'max_depth': 8, 'learning_rate': np.float64(0.38)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 파라미터 최적화 결과"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for idx, best_model in enumerate(model_best_estimators):\n",
    "#     y_pred = best_model.predict(X_test)\n",
    "#     print(f'{file_names[idx]}')\n",
    "#     evaluate_score(y_test, y_pred)\n",
    "#     print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lr_clf.joblib\n",
    "precision: 0.915068, recall: 0.920110\n",
    "\n",
    "dt_clf.joblib\n",
    "precision: 0.920732, recall: 0.831956\n",
    "\n",
    "svm_clf.joblib\n",
    "precision: 0.928375, recall: 0.928375\n",
    "\n",
    "knn_clf.joblib\n",
    "precision: 0.881844, recall: 0.842975\n",
    "\n",
    "xgb_clf.joblib\n",
    "precision: 0.940054, recall: 0.950413\n",
    "\n",
    "lgbm_clf.joblib\n",
    "precision: 0.945055, recall: 0.947658\n",
    "\n",
    "hist_gb_clf.joblib\n",
    "precision: 0.942466, recall: 0.947658"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 성능 좋은 3가지 모델로 앙상블"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "# voting_clf = VotingClassifier(estimators = [\n",
    "#                                             (\"svm_clf\", model_best_estimators[2]),\n",
    "#                                             (\"xgb_clf\", model_best_estimators[4]),\n",
    "#                                             (\"hist_gb_clf\", model_best_estimators[6]),\n",
    "#                                             ],\n",
    "#                               voting = \"hard\")\n",
    "\n",
    "# voting_clf.fit(X_train, y_train)\n",
    "# y_pred = voting_clf.predict(X_test)\n",
    "# evaluate_score(y_test, y_pred)\n",
    "\n",
    "# dump(voting_clf, 'voting_clf.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "precision: 0.945504, recall: 0.955923"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "first_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
